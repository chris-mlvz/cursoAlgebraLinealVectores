{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0c72a629dba5ae9edebcad565c17c3988d814021371aabb3db62cb04d2b10dbfe",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Producto interno (escalar o punto)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,0,0,0]) #declaramos el vector e_1\n",
    "\n",
    "b = np.array([0,0,1,0]) #declaramos el vector e_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<a,b> = 0\n"
     ]
    }
   ],
   "source": [
    "print('<a,b> =',np.dot(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<a,b> = 0\n"
     ]
    }
   ],
   "source": [
    "print('<a,b> =',a.T@b)"
   ]
  },
  {
   "source": [
    "## Evaluación de poliomios"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p(x):\n",
    "    return np.array([1,2])@np.array([1,x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "p(0) =  1\np(1) =  3\np(2) =  5\n"
     ]
    }
   ],
   "source": [
    "print('p(0) = ',p(0))\n",
    "print('p(1) = ',p(1))\n",
    "print('p(2) = ',p(2))"
   ]
  },
  {
   "source": [
    "# Ejercicios"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Problema 1: Análisis de sentimiento de tweets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweets\n",
    "A = \"Gran mexicano y excelente en su área, su muerte es una enorme perdida y debería ser luto nacional!!!\"\n",
    "B =\"Vaya señora que bueno que se asesora por alguien inteligente no por el ignorante del Gatt.\"\n",
    "C =  \"Se me ocurre y sin ver todos los videos de Plazti que me informéis por dónde empiezo. Entiendo que os tendría que decir quién soy y que quiero, vamos conocerme para asesorarme bien. Un saludo\"\n",
    "D = \"Soy docente universitario, estoy intentando preparar mis clases en modo platzi bien didáctico, (le llamo modo noticiero), descargue una plataforma gratuita de grabación y transmisión de vídeo, se llama Obs estudio!bueno la sigo remando con sus funciones pero sé que saldrá algo!\"\n",
    "TWEETS = (A,B,C,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [],
   "source": [
    "PST_WORDS = (\"excelente\",\"gran\",\"quiero\",\"positivo\",'bien','positivo','bueno','inteligente')\n",
    "\n",
    "NTR_WORDS = (\"pérdida\",'aprender','estudio','platzi')\n",
    "\n",
    "NGT_WORDS = (\"muerte\",\"luto\",'ignorante')\n",
    "\n",
    "PST_WORDS = tuple(set(PST_WORDS))\n",
    "NTR_WORDS = tuple(set(NTR_WORDS))\n",
    "NGT_WORDS = tuple(set(NGT_WORDS))\n",
    "WORDS = PST_WORDS + NGT_WORDS + NTR_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_tweets(tweets: tuple) -> list:\n",
    "    tweets_list = []\n",
    "    for tweet in tweets:\n",
    "        for i in \"!().,\":\n",
    "            tweet = tweet.replace(i,\"\")\n",
    "            tweet = tweet.lower()\n",
    "        list_tweet = tweet.split()\n",
    "        tweets_list.append(list_tweet)\n",
    "    return tweets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_list = normalize_tweets(TWEETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counting_words(words: tuple, tweets_list: list) -> list:\n",
    "    counted_words_list = []\n",
    "    counted_words_vector = []\n",
    "\n",
    "    for i in tweets_list:\n",
    "        cw_dict = {}\n",
    "        all_words_dict = Counter(i)\n",
    "\n",
    "        for word in words:\n",
    "            cw_dict[word] = all_words_dict.get(word,0)\n",
    "\n",
    "        counted_words_list.append(cw_dict)\n",
    "        counted_words_vector.append(list(cw_dict.values()))\n",
    "\n",
    "    return counted_words_list, np.array(counted_words_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0]])"
      ]
     },
     "metadata": {},
     "execution_count": 927
    }
   ],
   "source": [
    "counted_words, w_vectors = counting_words(WORDS, tweets_list)\n",
    "w_vectors\n",
    "# array([[0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
    "#        [0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
    "#        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "#        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classified_vectors(counted_words:list, pst_words:tuple, ngt_words:tuple, ntr_words:tuple) -> list:\n",
    "    classified_vector = []\n",
    "\n",
    "    for cw_dict in words_counted:\n",
    "        temp_list = [0,0,0]\n",
    "        for word in pst_words:\n",
    "            temp_list[0] += cw_dict.get(word,0)\n",
    "        for word in ngt_words:\n",
    "            temp_list[1] += cw_dict.get(word,0)\n",
    "        for word in ntr_words:\n",
    "            temp_list[2] += cw_dict.get(word,0)\n",
    "        classified_vector.append(temp_list)\n",
    "\n",
    "    return np.array(classified_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[2, 2, 0],\n",
       "       [2, 1, 0],\n",
       "       [2, 0, 0],\n",
       "       [1, 0, 1]])"
      ]
     },
     "metadata": {},
     "execution_count": 929
    }
   ],
   "source": [
    "s_vectors = classified_vectors(counted_words, PST_WORDS, NGT_WORDS, NTR_WORDS)\r\n",
    "s_vectors\r\n",
    "\r\n",
    "# array([[2, 2, 0],\r\n",
    "#        [2, 1, 0],\r\n",
    "#        [2, 0, 0],\r\n",
    "#        [1, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgs_vectors(vectors):\n",
    "    avgs = []\n",
    "    for i in vectors:\n",
    "        avg_i = (np.ones(i.size) / i.size).T@i\n",
    "        avgs.append(avg_i)\n",
    "    return np.array(avgs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([0.28571429, 0.21428571, 0.14285714, 0.14285714]),\n",
       " array([1.33333333, 1.        , 0.66666667, 0.66666667]))"
      ]
     },
     "metadata": {},
     "execution_count": 931
    }
   ],
   "source": [
    "avgs_w = avgs_vectors(w_vectors) \n",
    "avgs_s = avgs_vectors(s_vectors) \n",
    "avgs_w, avgs_s\n",
    "# (array([0.28571429, 0.21428571, 0.14285714, 0.14285714]),\n",
    "#  array([1.33333333, 1.        , 0.66666667, 0.66666667]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pro_s(vectors):\n",
    "    avgs = []\n",
    "    for i in vectors:\n",
    "        avg_i = i / np.sum(i)\n",
    "        avgs.append(avg_i)\n",
    "    return np.array(avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.5        0.5        0.        ]\n [0.66666667 0.33333333 0.        ]\n [1.         0.         0.        ]\n [0.5        0.         0.5       ]]\n"
     ]
    }
   ],
   "source": [
    "P_s = Pro_s(s_vectors)\n",
    "P_s\n",
    "P_s_T=P_s.T\n",
    "print(P_s)\n",
    "# [[0.5        0.5        0.        ]\n",
    "#  [0.66666667 0.33333333 0.        ]\n",
    "#  [1.         0.         0.        ]\n",
    "#  [0.5        0.         0.5       ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(s_vectors):\n",
    "    scores = []\n",
    "    for s in s_vectors:\n",
    "        score = np.array((1, 0, -1)).dot(s)\n",
    "        scores.append(score)\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([2, 2, 2, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 935
    }
   ],
   "source": [
    "scores = score(s_vectors)\n",
    "scores\n",
    "#array([2, 2, 2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Gran mexicano y excelente en su área, su muerte es una enorme perdida y debería ser luto nacional!!!'"
      ]
     },
     "metadata": {},
     "execution_count": 936
    }
   ],
   "source": [
    "# Tweet más positivo\n",
    "TWEETS[np.argmax(scores)]\n",
    "\n",
    "# 'Gran mexicano y excelente en su área, su muerte es una enorme perdida y debería ser luto nacional!!!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Soy docente universitario, estoy intentando preparar mis clases en modo platzi bien didáctico, (le llamo modo noticiero), descargue una plataforma gratuita de grabación y transmisión de vídeo, se llama Obs estudio!bueno la sigo remando con sus funciones pero sé que saldrá algo!'"
      ]
     },
     "metadata": {},
     "execution_count": 937
    }
   ],
   "source": [
    "# Tweet más negativo\n",
    "TWEETS[np.argmin(scores)]\n",
    "# 'Soy docente universitario, estoy intentando preparar mis clases en modo platzi bien didáctico, (le llamo modo noticiero), descargue una plataforma gratuita de grabación y transmisión de vídeo, se llama Obs estudio!bueno la sigo remando con sus funciones pero sé que saldrá algo!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'1.5'"
      ]
     },
     "metadata": {},
     "execution_count": 938
    }
   ],
   "source": [
    "# Calidad promedio\n",
    "np.mean(scores)\n",
    "\"1.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpretación de avg(s) y score(s)\n",
    "\n",
    "#avg(s) te permite identificar la cantidad de palabras encontradas que se pudieron clasificar, un bajo promedio siginifica que no se encontraron palabras por lo que el modelo es menos preciso y un mayor promedio indica mayor precisión.\n",
    "\n",
    "#score(s) te permite saber si un tweet contiene más palabras, positivas,negativas o neutras dependiendo su valor. Mayor score indica más palabar positivas, menor score palabras negativas y valor cercano a 0 significa que las palabras estan balanceadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relacion de la calidad con socre(s) y avg(s)\n",
    "\n",
    "# A mayor calidad, tendremos más datos para confirmar que tanto el score como el avg son correctos, con poca calidad los datos del score y avg son poco representativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {\"Tweet\":TWEETS, \"Calidad(w)\":avgs_w, \"Calidad(s)\":avgs_s, \"P+\":P_s_T[0],\"Pn\":P_s_T[2],\n",
    "\"P-\":P_s_T[1], \"Score\":scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               Tweet  Calidad(w)  Calidad(s)  \\\n",
       "0  Gran mexicano y excelente en su área, su muert...    0.285714    1.333333   \n",
       "1  Vaya señora que bueno que se asesora por algui...    0.214286    1.000000   \n",
       "2  Se me ocurre y sin ver todos los videos de Pla...    0.142857    0.666667   \n",
       "3  Soy docente universitario, estoy intentando pr...    0.142857    0.666667   \n",
       "\n",
       "         P+   Pn        P-  Score  \n",
       "0  0.500000  0.0  0.500000      2  \n",
       "1  0.666667  0.0  0.333333      2  \n",
       "2  1.000000  0.0  0.000000      2  \n",
       "3  0.500000  0.5  0.000000      0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweet</th>\n      <th>Calidad(w)</th>\n      <th>Calidad(s)</th>\n      <th>P+</th>\n      <th>Pn</th>\n      <th>P-</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Gran mexicano y excelente en su área, su muert...</td>\n      <td>0.285714</td>\n      <td>1.333333</td>\n      <td>0.500000</td>\n      <td>0.0</td>\n      <td>0.500000</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Vaya señora que bueno que se asesora por algui...</td>\n      <td>0.214286</td>\n      <td>1.000000</td>\n      <td>0.666667</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Se me ocurre y sin ver todos los videos de Pla...</td>\n      <td>0.142857</td>\n      <td>0.666667</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Soy docente universitario, estoy intentando pr...</td>\n      <td>0.142857</td>\n      <td>0.666667</td>\n      <td>0.500000</td>\n      <td>0.5</td>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 944
    }
   ],
   "source": [
    "df\n",
    "# Tweet\tCalidad(w)\tCalidad(s)\tP+\tPn\tP-\tScore\n",
    "# 0\tGran mexicano y excelente en su área, su muert...\t0.285714\t1.333333\t0.500000\t0.0\t0.500000\t2\n",
    "# 1\tVaya señora que bueno que se asesora por algui...\t0.214286\t1.000000\t0.666667\t0.0\t0.333333\t2\n",
    "# 2\tSe me ocurre y sin ver todos los videos de Pla...\t0.142857\t0.666667\t1.000000\t0.0\t0.000000\t2\n",
    "# 3\tSoy docente universitario, estoy intentando pr...\t0.142857\t0.666667\t0.500000\t0.5\t0.000000\t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}